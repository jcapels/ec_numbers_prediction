{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from ec_number_prediction.data_processing_pipeline.cdhit_clusters import ClustersIdentifier\n",
    "\n",
    "clusters = ClustersIdentifier.from_files(identity_threshold=80, folder=\"./data/clusters/\", filename='all_sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4003680/967182109.py:3: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged_dataset = pd.read_csv(\"../data/merged_dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merged_dataset = pd.read_csv(\"../data/merged_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "representatives = []\n",
    "for cluster in clusters.cluster_to_members:\n",
    "    element = np.random.choice(np.array(clusters.cluster_to_members[cluster].members), size=1)\n",
    "    representatives.append(element[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "representatives_dataset = merged_dataset[merged_dataset[\"accession\"].isin(representatives)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import IterativeStratification\n",
    "\n",
    "def apply_stratification_sklearn(X: np.ndarray, y: np.ndarray, test_size: float = 0.15, train_size: float = 0.85, n_splits=2):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Samples\n",
    "    y : np.ndarray\n",
    "        Labels\n",
    "    test_size : float, optional\n",
    "        Size of the test set, by default 0.15\n",
    "    train_size : float, optional\n",
    "        Size of the train set, by default 0.85\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n",
    "        X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    stratifier = IterativeStratification(n_splits=n_splits, order=1, sample_distribution_per_fold=[test_size]*n_splits)\n",
    "\n",
    "    folds = []\n",
    "    for train_indexes, test_indexes  in stratifier.split(X, y):\n",
    "        X_train = X.iloc[train_indexes]\n",
    "        y_train = y.iloc[train_indexes, :]\n",
    "\n",
    "        X_test = X.iloc[test_indexes]\n",
    "        y_test = y.iloc[test_indexes, :]\n",
    "\n",
    "        folds.append((X_train, y_train, X_test, y_test))\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats(y_train: np.ndarray, y_test: np.ndarray, y_val: np.ndarray=None):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_train : np.ndarray\n",
    "        Labels of the train set\n",
    "    y_test : np.ndarray\n",
    "        Labels of the test set\n",
    "    y_val : np.ndarray, optional\n",
    "        Labels of the validation set, by default None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[pd.DataFrame, Any]\n",
    "        DataFrame with the stats of the split, styled table\n",
    "    \"\"\"\n",
    "    y_test_sum = np.sum(y_test)\n",
    "    y_train_sum = np.sum(y_train)\n",
    "\n",
    "    sum_of_all = pd.DataFrame([y_train_sum, y_test_sum], index=[\"train\", \"test\"])\n",
    "\n",
    "    if y_val is not None:\n",
    "        y_val_sum = np.sum(y_val)\n",
    "        sum_of_all = pd.DataFrame([y_train_sum, y_test_sum, y_val_sum], index=[\"train\", \"test\", \"validation\"])\n",
    "        sum_of_all.loc['Validation relative split', :] = sum_of_all.loc['validation', :] / (sum_of_all.loc['train', :] + sum_of_all.loc['test', :] + sum_of_all.loc['validation', :]) * 100\n",
    "        sum_of_all.loc['Test relative split', :] = sum_of_all.loc['test', :] / (sum_of_all.loc['train', :] + sum_of_all.loc['test', :]+ sum_of_all.loc['validation', :]) * 100\n",
    "        sum_of_all.loc['Train relative split', :] = sum_of_all.loc['train', :] / (sum_of_all.loc['train', :] + sum_of_all.loc['test', :]+ sum_of_all.loc['validation', :]) * 100\n",
    "\n",
    "    else:\n",
    "        sum_of_all.loc['Test relative split', :] = sum_of_all.loc['test', :] / (sum_of_all.loc['train', :] + sum_of_all.loc['test', :]) * 100\n",
    "        sum_of_all.loc['Train relative split', :] = sum_of_all.loc['train', :] / (sum_of_all.loc['train', :] + sum_of_all.loc['test', :]) * 100\n",
    "\n",
    "    df = pd.melt(sum_of_all.T.reset_index(), id_vars=['index']).rename(columns={'index': 'EC', 'value': 'Percentage of data'})\n",
    "    if y_val is not None:\n",
    "        df = df[(df[\"variable\"]!=\"train\") & (df[\"variable\"]!=\"validation\") & (df[\"variable\"]!=\"test\")]\n",
    "    else: \n",
    "        df = df[(df[\"variable\"]!=\"train\") & (df[\"variable\"]!=\"test\")]\n",
    "\n",
    "    df1 = sum_of_all.loc['Test relative split', :].describe()\n",
    "    df2 = sum_of_all.loc['Train relative split', :].describe()\n",
    "    if y_val is not None:\n",
    "        df3 = sum_of_all.loc['Validation relative split', :].describe()\n",
    "        stats_table = pd.concat([df1, df2, df3], axis=1)\n",
    "    else:\n",
    "        stats_table = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    stats_table.drop(['count'], inplace=True)\n",
    "    table_styled = stats_table.style.background_gradient(cmap=\"YlGn\")\n",
    "    \n",
    "\n",
    "    return df, table_styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = representatives_dataset.loc[:, \"accession\"]\n",
    "y = representatives_dataset.iloc[:, 8:]\n",
    "y = y.astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_algorithm(X, y, test_size=0.20):\n",
    "    # Calculate the sum of y for each unique class\n",
    "    y_sum = y.sum()\n",
    "    sorted_indices = np.argsort(y_sum)\n",
    "\n",
    "    # Initialize mapping and counts\n",
    "    ec_to_accessions = {}\n",
    "    remaining_ecs = y_sum.index[sorted_indices].tolist()\n",
    "    remaining_ecs_counts = y_sum.values[sorted_indices].tolist()\n",
    "\n",
    "    # Build the ec_to_accessions mapping using vectorized operations\n",
    "    for ec in remaining_ecs:\n",
    "        cases = y[y[ec] == 1].index\n",
    "        ec_to_accessions[ec] = X.loc[cases]\n",
    "\n",
    "    # Initialize train and test datasets\n",
    "    X_test_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    # Keep track of indexes to drop later\n",
    "    indexes_to_drop = []\n",
    "\n",
    "    for i, ec in enumerate(tqdm(remaining_ecs, desc=\"Splitting\")):\n",
    "        counts = remaining_ecs_counts[i]\n",
    "        \n",
    "        if i == 0:\n",
    "            # Sample initial set of ECs for the test set\n",
    "            cases = y[y[ec] == 1]\n",
    "            n_samples = max(1, round(test_size * cases.shape[0]))\n",
    "            indexes = cases.sample(n=n_samples, random_state=123).index\n",
    "\n",
    "            # Collect results in lists for final concatenation\n",
    "            X_test_list.append(X.loc[indexes])\n",
    "            y_test_list.append(y.loc[indexes])\n",
    "\n",
    "            # Track indexes to drop\n",
    "            indexes_to_drop.extend(indexes)\n",
    "        else:\n",
    "            # Check how many cases of the current EC are already in the test set\n",
    "            cases_ec_test = len(X_test_list) and np.isin(ec_to_accessions[ec], X_test_list).sum()\n",
    "            total_to_add = test_size - (cases_ec_test / counts)\n",
    "\n",
    "            if total_to_add > 0.05:\n",
    "\n",
    "\n",
    "                # Sample from the remaining training set\n",
    "                available_cases = X.loc[~X.index.isin(indexes_to_drop) & X.isin(ec_to_accessions[ec])]\n",
    "                n_samples = max(1, round(total_to_add * available_cases.shape[0]))\n",
    "                indexes = available_cases.sample(n=n_samples, random_state=123).index\n",
    "\n",
    "                # Collect results in lists for final concatenation\n",
    "                X_test_list.append(X.loc[indexes])\n",
    "                y_test_list.append(y.loc[indexes])\n",
    "\n",
    "                # Track indexes to drop\n",
    "                indexes_to_drop.extend(indexes)\n",
    "\n",
    "    # Concatenate the results once at the end\n",
    "    X_test = pd.concat(X_test_list, ignore_index=True)\n",
    "    y_test = pd.concat(y_test_list, ignore_index=True)\n",
    "\n",
    "    # Drop selected indexes from training datasets in one go\n",
    "    X_train = X.drop(indexes_to_drop)\n",
    "    y_train = y.drop(indexes_to_drop)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = apply_stratification_sklearn(X, y, n_splits=5, test_size=0.20)\n",
    "stats = []\n",
    "for i, fold in enumerate(folds):\n",
    "    X_train, y_train, X_test, y_test = fold\n",
    "    df_with_stats, table_styled = generate_stats(y_train, y_test)\n",
    "    \n",
    "    stats.append(table_styled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folds = []\n",
    "\n",
    "for fold in folds:\n",
    "    X_train, y_train, X_test, y_test = fold\n",
    "    test = merged_dataset[merged_dataset[\"accession\"].isin(X_test)]\n",
    "    test_folds.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_of_train_datasets = []\n",
    "rest_of_test_datasets = []\n",
    "\n",
    "for fold in folds:\n",
    "    X_train, y_train, X_test, y_test = fold\n",
    "    rest_of_train_dataset = []\n",
    "    rest_of_test_dataset = []\n",
    "    for accession in X_train:\n",
    "        cluster = clusters.get_cluster_by_member(accession).members\n",
    "        rest_of_train_dataset.extend(cluster)\n",
    "\n",
    "    for accession in X_test:\n",
    "        cluster = clusters.get_cluster_by_member(accession).members\n",
    "        rest_of_test_dataset.extend(cluster)\n",
    "\n",
    "    rest_of_train_datasets.append(rest_of_train_dataset)\n",
    "    rest_of_test_datasets.append(rest_of_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = []\n",
    "test_datasets = []\n",
    "for i, fold in enumerate(folds): \n",
    "    train = merged_dataset[merged_dataset[\"accession\"].isin(rest_of_train_datasets[i])]\n",
    "    test = merged_dataset[merged_dataset[\"accession\"].isin(rest_of_test_datasets[i])]\n",
    "\n",
    "    train_datasets.append(train)\n",
    "    test_datasets.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.loc[:, \"accession\"]\n",
    "y_train = train_dataset.iloc[:, 8:]\n",
    "y_train = y_train.astype(float).astype(int)\n",
    "\n",
    "X_test = test_dataset.loc[:, \"accession\"]\n",
    "y_test = test_dataset.iloc[:, 8:]\n",
    "y_test = y_test.astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d436c_row0_col0, #T_d436c_row4_col0 {\n",
       "  background-color: #dbf1a4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d436c_row0_col1 {\n",
       "  background-color: #187b3f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d436c_row1_col0 {\n",
       "  background-color: #fbfdce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d436c_row1_col1, #T_d436c_row2_col0 {\n",
       "  background-color: #ffffe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d436c_row2_col1 {\n",
       "  background-color: #f6fcb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d436c_row3_col0 {\n",
       "  background-color: #e3f4aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d436c_row3_col1 {\n",
       "  background-color: #218242;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d436c_row4_col1 {\n",
       "  background-color: #177b3f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d436c_row5_col0 {\n",
       "  background-color: #cfec9e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d436c_row5_col1 {\n",
       "  background-color: #10743c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d436c_row6_col0, #T_d436c_row6_col1 {\n",
       "  background-color: #004529;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d436c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d436c_level0_col0\" class=\"col_heading level0 col0\" >Test relative split</th>\n",
       "      <th id=\"T_d436c_level0_col1\" class=\"col_heading level0 col1\" >Train relative split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d436c_level0_row0\" class=\"row_heading level0 row0\" >mean</th>\n",
       "      <td id=\"T_d436c_row0_col0\" class=\"data row0 col0\" >20.031162</td>\n",
       "      <td id=\"T_d436c_row0_col1\" class=\"data row0 col1\" >79.968838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d436c_level0_row1\" class=\"row_heading level0 row1\" >std</th>\n",
       "      <td id=\"T_d436c_row1_col0\" class=\"data row1 col0\" >5.483510</td>\n",
       "      <td id=\"T_d436c_row1_col1\" class=\"data row1 col1\" >5.483510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d436c_level0_row2\" class=\"row_heading level0 row2\" >min</th>\n",
       "      <td id=\"T_d436c_row2_col0\" class=\"data row2 col0\" >0.000000</td>\n",
       "      <td id=\"T_d436c_row2_col1\" class=\"data row2 col1\" >18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d436c_level0_row3\" class=\"row_heading level0 row3\" >25%</th>\n",
       "      <td id=\"T_d436c_row3_col0\" class=\"data row3 col0\" >17.000000</td>\n",
       "      <td id=\"T_d436c_row3_col1\" class=\"data row3 col1\" >77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d436c_level0_row4\" class=\"row_heading level0 row4\" >50%</th>\n",
       "      <td id=\"T_d436c_row4_col0\" class=\"data row4 col0\" >19.868996</td>\n",
       "      <td id=\"T_d436c_row4_col1\" class=\"data row4 col1\" >80.131004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d436c_level0_row5\" class=\"row_heading level0 row5\" >75%</th>\n",
       "      <td id=\"T_d436c_row5_col0\" class=\"data row5 col0\" >23.000000</td>\n",
       "      <td id=\"T_d436c_row5_col1\" class=\"data row5 col1\" >83.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d436c_level0_row6\" class=\"row_heading level0 row6\" >max</th>\n",
       "      <td id=\"T_d436c_row6_col0\" class=\"data row6 col0\" >82.000000</td>\n",
       "      <td id=\"T_d436c_row6_col1\" class=\"data row6 col1\" >100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f457f6033a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_stats, table_styled = generate_stats(y_train, y_test)\n",
    "table_styled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
