{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Test models on the halogenases dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# define the directory where the data is\n",
    "data_path = \"/home/joao/Desktop/required_data_ec_number_paper/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create useful functions to post process the predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_unique_labels_by_level(dataset, level):\n",
    "    final_dataset_test = dataset.copy()\n",
    "    final_dataset_test = final_dataset_test.loc[:,level]\n",
    "    final_dataset_test.fillna(\"0\", inplace=True)\n",
    "    values = pd.Series(final_dataset_test.values.reshape(-1)).str.split(\";\")\n",
    "    list_of_unique_labels = np.unique(values.explode()).tolist()\n",
    "    if \"0\" in list_of_unique_labels:\n",
    "        list_of_unique_labels.remove(\"0\")\n",
    "    list_of_unique_labels_dict = dict(zip(list_of_unique_labels, range(len(list_of_unique_labels))))\n",
    "    return list_of_unique_labels_dict\n",
    "\n",
    "def get_final_labels(dataset, all_levels=False):\n",
    "\n",
    "    if all_levels:\n",
    "        unique_EC1 = get_unique_labels_by_level(dataset, \"EC1\")\n",
    "        unique_EC2 = get_unique_labels_by_level(dataset, \"EC2\")\n",
    "        unique_EC3 = get_unique_labels_by_level(dataset, \"EC3\")\n",
    "        \n",
    "        array_EC1 = np.zeros((len(dataset), len(unique_EC1)))\n",
    "        array_EC2 = np.zeros((len(dataset), len(unique_EC2)))\n",
    "        array_EC3 = np.zeros((len(dataset), len(unique_EC3)))\n",
    "\n",
    "    unique_EC4 = get_unique_labels_by_level(dataset, \"EC4\")\n",
    "\n",
    "    array_EC4 = np.zeros((len(dataset), len(unique_EC4)))\n",
    "        \n",
    "    dataset.fillna(\"0\", inplace=True)\n",
    "\n",
    "    if all_levels:\n",
    "        for i, row in dataset.iterrows():\n",
    "            for ec in [\"EC1\", \"EC2\", \"EC3\", \"EC4\"]:\n",
    "                for EC in row[ec].split(\";\"):\n",
    "                    if EC != \"0\":\n",
    "                        if ec == \"EC1\":\n",
    "                            array_EC1[i, unique_EC1[EC]] = 1\n",
    "                        elif ec == \"EC2\":\n",
    "                            array_EC2[i, unique_EC2[EC]] = 1\n",
    "                        elif ec == \"EC3\":\n",
    "                            array_EC3[i, unique_EC3[EC]] = 1\n",
    "                        elif ec == \"EC4\":\n",
    "                            array_EC4[i, unique_EC4[EC]] = 1\n",
    "    else:\n",
    "        for i, row in dataset.iterrows():\n",
    "            for EC in row[\"EC4\"].split(\";\"):\n",
    "                if EC != \"0\":\n",
    "                    array_EC4[i, unique_EC4[EC]] = 1\n",
    "    if all_levels:\n",
    "        array_EC1 = pd.DataFrame(array_EC1, columns=unique_EC1.keys())\n",
    "        array_EC2 = pd.DataFrame(array_EC2, columns=unique_EC2.keys())\n",
    "        array_EC3 = pd.DataFrame(array_EC3, columns=unique_EC3.keys())\n",
    "    array_EC4 = pd.DataFrame(array_EC4, columns=unique_EC4.keys())\n",
    "\n",
    "    if all_levels:\n",
    "        dataset = pd.concat((dataset, array_EC1, array_EC2, array_EC3, array_EC4), axis=1)\n",
    "    else:\n",
    "        dataset = pd.concat((dataset, array_EC4), axis=1)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_ec_from_regex_match(match):\n",
    "    if match is not None:\n",
    "        EC = match.group()\n",
    "        if EC is not None:\n",
    "            return EC\n",
    "    return None\n",
    "\n",
    "def get_labels_based_on_list(dataset, labels, all_levels=True):\n",
    "    array = np.zeros((len(dataset), len(labels)))\n",
    "    labels_dataframe = pd.DataFrame(array, columns=labels)\n",
    "    dataset.fillna(\"0\", inplace=True)\n",
    "    for i, row in dataset.iterrows():\n",
    "        for label in row[\"EC4\"].split(\";\"):\n",
    "            if label != \"0\" and label in labels:\n",
    "                labels_dataframe.at[i, label] = 1\n",
    "        \n",
    "        if all_levels:\n",
    "            for ec in [\"EC1\", \"EC2\", \"EC3\"]:\n",
    "                for label in row[ec].split(\";\"):\n",
    "                    if label != \"0\" and label in labels:\n",
    "                        labels_dataframe.at[i, label] = 1\n",
    "\n",
    "    return pd.concat((dataset, labels_dataframe), axis=1)\n",
    "\n",
    "def divide_labels_by_EC_level(final_dataset, ec_label):\n",
    "    EC1_lst = []\n",
    "    EC2_lst = []\n",
    "    EC3_lst = []\n",
    "    EC4_lst = []\n",
    "\n",
    "\n",
    "    for _, row in final_dataset.iterrows():\n",
    "        ECs = row[ec_label]\n",
    "        ECs = ECs.split(\";\")\n",
    "        # get the first 3 ECs with regular expression\n",
    "        EC3 = []\n",
    "        EC2 = []\n",
    "        EC1 = []\n",
    "        EC4 = []\n",
    "        for EC in ECs:\n",
    "            new_EC = re.search(r\"^\\d+.\\d+.\\d+.n*\\d+\", EC)\n",
    "            new_EC = get_ec_from_regex_match(new_EC)\n",
    "            if isinstance(new_EC, str):\n",
    "                if new_EC not in EC4:\n",
    "                    EC4.append(new_EC)\n",
    "\n",
    "            new_EC = re.search(r\"^\\d+.\\d+.\\d+\", EC)\n",
    "            new_EC = get_ec_from_regex_match(new_EC)\n",
    "            if isinstance(new_EC, str):\n",
    "                if new_EC not in EC3:\n",
    "                    EC3.append(new_EC)\n",
    "\n",
    "            new_EC = re.search(r\"^\\d+.\\d+\", EC)\n",
    "            new_EC = get_ec_from_regex_match(new_EC)\n",
    "            if isinstance(new_EC, str):\n",
    "                if new_EC not in EC2:\n",
    "                    EC2.append(new_EC)\n",
    "\n",
    "            new_EC = re.search(r\"^\\d+\", EC)\n",
    "            new_EC = get_ec_from_regex_match(new_EC)\n",
    "            if isinstance(new_EC, str):\n",
    "                if new_EC not in EC1:\n",
    "                    EC1.append(new_EC)\n",
    "\n",
    "        if len(EC4) == 0:\n",
    "            EC4_lst.append(np.NaN)\n",
    "        else:\n",
    "            EC4_lst.append(\";\".join(EC4))\n",
    "        if len(EC3) == 0:\n",
    "            EC3_lst.append(np.NaN)\n",
    "        else:\n",
    "            EC3_lst.append(\";\".join(EC3))\n",
    "        if len(EC2) == 0:\n",
    "            EC2_lst.append(np.NaN)\n",
    "        else:\n",
    "            EC2_lst.append(\";\".join(EC2))\n",
    "        if len(EC1) == 0:\n",
    "            EC1_lst.append(np.NaN)\n",
    "        else:\n",
    "            EC1_lst.append(\";\".join(EC1))\n",
    "\n",
    "    assert None not in EC1_lst\n",
    "    assert None not in EC2_lst\n",
    "    assert None not in EC3_lst\n",
    "    assert None not in EC4_lst\n",
    "\n",
    "    assert len(EC1_lst) == len(final_dataset)\n",
    "    assert len(EC2_lst) == len(final_dataset)\n",
    "    assert len(EC3_lst) == len(final_dataset)\n",
    "    assert len(EC4_lst) == len(final_dataset)\n",
    "\n",
    "    final_dataset[\"EC1\"] = EC1_lst\n",
    "    final_dataset[\"EC2\"] = EC2_lst\n",
    "    final_dataset[\"EC3\"] = EC3_lst\n",
    "    final_dataset[\"EC4\"] = EC4_lst\n",
    "\n",
    "    assert final_dataset[\"EC1\"].isnull().sum() == 0\n",
    "    print(\"EC1 is not null\")\n",
    "\n",
    "    return final_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_ec_levels(labels):\n",
    "    level_1 = []\n",
    "    level_2 = []\n",
    "    level_3 = []\n",
    "    level_4 = []\n",
    "    for i, label in enumerate(labels):\n",
    "        if re.match(r\"^\\d+.\\d+.\\d+.n*\\d+$\", label):\n",
    "            level_4.append(i)\n",
    "        elif re.match(r\"^\\d+.\\d+.\\d+$\", label):\n",
    "            level_3.append(i)\n",
    "        elif re.match(r\"^\\d+.\\d+$\", label):\n",
    "            level_2.append(i)\n",
    "        elif re.match(r\"^\\d+$\", label):\n",
    "            level_1.append(i)\n",
    "    return level_1, level_2, level_3, level_4\n",
    "\n",
    "def get_metrics(y_true, predictions, labels, labels_to_remove, model_name):\n",
    "\n",
    "    y_true_ = np.delete(y_true, labels_to_remove, axis=1)\n",
    "    predictions_ = np.delete(predictions, labels_to_remove, axis=1)\n",
    "    labels_ = np.delete(labels, labels_to_remove)\n",
    "    level_1, level_2, level_3, level_4 = get_ec_levels(labels_)\n",
    "    print(\"level 1\", len(level_1))\n",
    "    print(\"level 2\", len(level_2))\n",
    "    print(\"level 3\", len(level_3))\n",
    "    print(\"level 4\", len(level_4))\n",
    "    \n",
    "    metrics = {}\n",
    "    # metrics[\"accuracy overall\"] = accuracy_score(y_true, predictions)\n",
    "    metrics[\"accuracy level 1\"] = accuracy_score(y_true_[:, level_1], predictions_[:, level_1])\n",
    "    metrics[\"accuracy level 2\"] = accuracy_score(y_true_[:, level_2], predictions_[:, level_2])\n",
    "    metrics[\"accuracy level 3\"] = accuracy_score(y_true_[:, level_3], predictions_[:, level_3])\n",
    "    metrics[\"accuracy level 4\"] = accuracy_score(y_true_[:, level_4], predictions_[:, level_4])\n",
    "\n",
    "    return pd.DataFrame(metrics, index=[model_name])\n",
    "\n",
    "def get_models_predictions(model, dataset, labels, labels_to_remove, model_name):\n",
    "    predictions = model.predict(dataset)\n",
    "    y_true = dataset.y\n",
    "\n",
    "    return get_metrics(y_true, predictions, labels, labels_to_remove, model_name)\n",
    "\n",
    "def convert_predictions_into_format(predictions, labels_names, new_labels):\n",
    "    new_predictions = np.zeros((len(predictions), len(new_labels)))\n",
    "    labels_names = np.array(labels_names)\n",
    "    new_labels = np.array(new_labels)\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        indexes = np.where(prediction == 1)\n",
    "        result = labels_names[indexes]\n",
    "        for res in result:\n",
    "            potential_result = new_labels[new_labels == res]\n",
    "            if potential_result.size > 0:\n",
    "                new_predictions[i, new_labels == res] = 1\n",
    "    return new_predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Read the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(f'{data_path}/data/halogenase.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plants_sm.data_structures.dataset.single_input_dataset import SingleInputDataset\n",
    "\n",
    "halogenases_dataset = SingleInputDataset.from_csv(f'{data_path}/data/halogenase.csv',\n",
    "                                            instances_ids_field=\"Entry\", representation_field=\"Sequence\", sep=\"\\t\",\n",
    "                                            nrows=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC1 is not null\n"
     ]
    }
   ],
   "source": [
    "h_dataset = pd.read_csv(f'{data_path}/data/halogenase.csv', sep=\"\\t\", nrows=36)\n",
    "h_dataset = divide_labels_by_EC_level(h_dataset, \"EC number\")\n",
    "h_dataset_ = get_final_labels(h_dataset, all_levels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plants_sm.data_structures.dataset.single_input_dataset import SingleInputDataset\n",
    "\n",
    "labels_names = SingleInputDataset.from_csv(f'{data_path}/data/merged_dataset.csv',\n",
    "                                           instances_ids_field=\"accession\", representation_field=\"sequence\",\n",
    "                                           labels_field=slice(8, -1), nrows=2).labels_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5743"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESM2 3B - get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plants_sm.models.fc.fc import DNN\n",
    "from plants_sm.models.pytorch_model import PyTorchModel\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "model = PyTorchModel(model = DNN(2560, [2560], 5743, batch_norm=True), loss_function=nn.BCELoss())\n",
    "model.model.load_state_dict(\n",
    "    torch.load(f'{data_path}/models/DNN_esm2_t36_3B_UR50D_optimization_set_2_all_data/pytorch_model_weights.pt', map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from plants_sm.data_standardization.proteins.standardization import ProteinStandardizer\n",
    "from plants_sm.data_standardization.truncation import Truncator\n",
    "from plants_sm.featurization.proteins.bio_embeddings.esm import ESMEncoder\n",
    "\n",
    "encoding = \"esm2_t36_3B_UR50D\"\n",
    "\n",
    "if not os.path.exists(f'{data_path}/features/test_halogenases_esm2_3b'):\n",
    "    transformers = [ProteinStandardizer(), Truncator(max_length=884), ESMEncoder(esm_function=encoding, batch_size=1, num_gpus=4)]\n",
    "    for transformer in transformers:\n",
    "        halogenases_dataset = transformer.fit_transform(halogenases_dataset)\n",
    "    halogenases_dataset.save_features(f'{data_path}/features/test_halogenases_esm2_3b')\n",
    "else:\n",
    "    halogenases_dataset.load_features(f'{data_path}/features/test_halogenases_esm2_3b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1 3\n",
      "level 2 4\n",
      "level 3 6\n",
      "level 4 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy level 1</th>\n",
       "      <th>accuracy level 2</th>\n",
       "      <th>accuracy level 3</th>\n",
       "      <th>accuracy level 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNN ESM2 3B</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.305556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accuracy level 1  accuracy level 2  accuracy level 3  \\\n",
       "DNN ESM2 3B          0.972222          0.972222          0.555556   \n",
       "\n",
       "             accuracy level 4  \n",
       "DNN ESM2 3B          0.305556  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(halogenases_dataset)\n",
    "new_predictions_esm2_3b = convert_predictions_into_format(predictions, labels_names, h_dataset_.iloc[:, 7:].columns)\n",
    "y_true = h_dataset_.iloc[:, 7:].values\n",
    "metrics_evaluation = get_metrics(y_true, new_predictions_esm2_3b, h_dataset_.iloc[:, 7:].columns, [], \"DNN ESM2 3B\")\n",
    "metrics_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5743"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESM1b - get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plants_sm.data_structures.dataset.single_input_dataset import SingleInputDataset\n",
    "\n",
    "halogenases_dataset = SingleInputDataset.from_csv(f'{data_path}/data/halogenase.csv',\n",
    "                                            instances_ids_field=\"Entry\", representation_field=\"Sequence\", sep=\"\\t\", nrows=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PyTorchModel(model = DNN(1280, [2560, 5120], 5743, batch_norm=True), loss_function=nn.BCELoss())\n",
    "model.model.load_state_dict(\n",
    "    torch.load(f'{data_path}/DNN_esm1b_t33_650M_UR50S_optimization_set_4_all_data/pytorch_model_weights.pt', map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from plants_sm.data_standardization.proteins.standardization import ProteinStandardizer\n",
    "from plants_sm.data_standardization.truncation import Truncator\n",
    "from plants_sm.featurization.proteins.bio_embeddings.esm import ESMEncoder\n",
    "\n",
    "encoding = \"esm1b_t33_650M_UR50S\"\n",
    "\n",
    "if not os.path.exists(f'{data_path}/features/test_halogenases_esm1b'):\n",
    "    transformers = [ProteinStandardizer(), Truncator(max_length=884), ESMEncoder(esm_function=encoding, batch_size=1, num_gpus=4)]\n",
    "    for transformer in transformers:\n",
    "        halogenases_dataset = transformer.fit_transform(halogenases_dataset)\n",
    "    halogenases_dataset.save_features(f'{data_path}/features/test_halogenases_esm1b')\n",
    "else:\n",
    "    halogenases_dataset.load_features(f'{data_path}/features/test_halogenases_esm1b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1 3\n",
      "level 2 4\n",
      "level 3 6\n",
      "level 4 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy level 1</th>\n",
       "      <th>accuracy level 2</th>\n",
       "      <th>accuracy level 3</th>\n",
       "      <th>accuracy level 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNN ESM2 3B</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN ESM1b</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accuracy level 1  accuracy level 2  accuracy level 3  \\\n",
       "DNN ESM2 3B          0.972222          0.972222          0.555556   \n",
       "DNN ESM1b            0.972222          0.972222          0.555556   \n",
       "\n",
       "             accuracy level 4  \n",
       "DNN ESM2 3B          0.305556  \n",
       "DNN ESM1b            0.333333  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(halogenases_dataset)\n",
    "new_predictions_esm1b = convert_predictions_into_format(predictions, labels_names, h_dataset_.iloc[:, 7:].columns)\n",
    "y_true = h_dataset_.iloc[:, 7:].values\n",
    "metrics_evaluation = pd.concat((metrics_evaluation, get_metrics(y_true, new_predictions_esm1b, h_dataset_.iloc[:, 7:].columns, [], \"DNN ESM1b\")))\n",
    "metrics_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProtBERT - get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plants_sm.data_structures.dataset.single_input_dataset import SingleInputDataset\n",
    "\n",
    "halogenases_dataset = SingleInputDataset.from_csv(f'{data_path}/data/halogenase.csv',\n",
    "                                            instances_ids_field=\"Entry\", representation_field=\"Sequence\", sep=\"\\t\", nrows=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plants_sm.models.pytorch_model import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(model = DNN(1024, [2560], 5743, batch_norm=True), loss_function=nn.BCELoss())\n",
    "model.model.load_state_dict(\n",
    "    torch.load(f'{data_path}/models/DNN_prot_bert_vectors_optimization_set_2_all_data/pytorch_model_weights.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "import os\n",
    "from plants_sm.featurization.proteins.bio_embeddings.prot_bert import ProtBert\n",
    "from plants_sm.data_standardization.proteins.standardization import ProteinStandardizer\n",
    "from plants_sm.data_standardization.truncation import Truncator\n",
    "\n",
    "if not os.path.exists(f'{data_path}/features/test_halogenases_prot_bert'):\n",
    "    transformers = [ProteinStandardizer(), Truncator(max_length=884), ProtBert(device=\"cuda:0\")]\n",
    "    for transformer in transformers:\n",
    "        halogenases_dataset = transformer.fit_transform(halogenases_dataset)\n",
    "    halogenases_dataset.save_features(f'{data_path}/features/test_halogenases_prot_bert')\n",
    "else:\n",
    "    halogenases_dataset.load_features(f'{data_path}/features/test_halogenases_prot_bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1 3\n",
      "level 2 4\n",
      "level 3 6\n",
      "level 4 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy level 1</th>\n",
       "      <th>accuracy level 2</th>\n",
       "      <th>accuracy level 3</th>\n",
       "      <th>accuracy level 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNN ESM2 3B</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN ESM1b</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN ProtBERT</th>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy level 1  accuracy level 2  accuracy level 3  \\\n",
       "DNN ESM2 3B           0.972222          0.972222          0.555556   \n",
       "DNN ESM1b             0.972222          0.972222          0.555556   \n",
       "DNN ProtBERT          0.861111          0.972222          0.583333   \n",
       "\n",
       "              accuracy level 4  \n",
       "DNN ESM2 3B           0.305556  \n",
       "DNN ESM1b             0.333333  \n",
       "DNN ProtBERT          0.250000  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(halogenases_dataset)\n",
    "new_predictions_protein_bert = convert_predictions_into_format(predictions, labels_names, h_dataset_.iloc[:, 7:].columns)\n",
    "y_true = h_dataset_.iloc[:, 7:].values\n",
    "metrics_evaluation = pd.concat((metrics_evaluation, get_metrics(y_true, new_predictions_protein_bert, h_dataset_.iloc[:, 7:].columns, [], \"DNN ProtBERT\")))\n",
    "metrics_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_evaluation.to_csv(\"metrics_evaluation_halogenases.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test ensemble models on the halogenases dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an ensemble of the predictions\n",
    "# make a voting classifier for the 3 models\n",
    "import numpy as np\n",
    "\n",
    "def determine_ensemble_predictions(threshold=3, *model_predictions):\n",
    "    model_predictions = list(model_predictions)\n",
    "\n",
    "    for i, model_prediction in enumerate(model_predictions):\n",
    "        model_predictions[i] = np.array(model_prediction)\n",
    "\n",
    "\n",
    "    predictions_voting = np.zeros_like(model_predictions[0])\n",
    "\n",
    "    for i in range(model_predictions[0].shape[0]):\n",
    "        # Combine conditions into a single array and sum along the second axis\n",
    "        combined_conditions = np.sum(np.array([model_predictions[j][i] for j in range(len(model_predictions))]), axis=0)\n",
    "\n",
    "        # Apply the threshold condition\n",
    "        predictions_voting[i] = (combined_conditions >= threshold).astype(int)\n",
    "\n",
    "    # If you want to ensure the resulting array is of integer type\n",
    "    predictions_voting = predictions_voting.astype(int)\n",
    "    return predictions_voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1 3\n",
      "level 2 4\n",
      "level 3 6\n",
      "level 4 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy level 1</th>\n",
       "      <th>accuracy level 2</th>\n",
       "      <th>accuracy level 3</th>\n",
       "      <th>accuracy level 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNN ESM2 3B</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN ESM1b</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN ProtBERT</th>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models Ensemble</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy level 1  accuracy level 2  accuracy level 3  \\\n",
       "DNN ESM2 3B              0.972222          0.972222          0.555556   \n",
       "DNN ESM1b                0.972222          0.972222          0.555556   \n",
       "DNN ProtBERT             0.861111          0.972222          0.583333   \n",
       "Models Ensemble          0.972222          0.972222          0.555556   \n",
       "\n",
       "                 accuracy level 4  \n",
       "DNN ESM2 3B              0.305556  \n",
       "DNN ESM1b                0.333333  \n",
       "DNN ProtBERT             0.250000  \n",
       "Models Ensemble          0.333333  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_ensemble = determine_ensemble_predictions(2, new_predictions_esm1b, new_predictions_protein_bert, new_predictions_esm2_3b)\n",
    "metrics_evaluation = pd.concat((metrics_evaluation, get_metrics(y_true, predictions_ensemble,  h_dataset_.iloc[:, 7:].columns, [], \"Models Ensemble\")))\n",
    "metrics_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_results = pd.read_csv(f'{data_path}/halogenase_blast_results.csv')\n",
    "blast_results.drop_duplicates(subset=[\"qseqid\"], inplace=True)\n",
    "# Create a new column with the custom order as a categorical type\n",
    "blast_results['CustomOrder'] = pd.Categorical(blast_results['qseqid'], categories=h_dataset.Entry, ordered=True)\n",
    "blast_results.sort_values('CustomOrder', inplace=True)\n",
    "blast_results.drop(columns=[\"CustomOrder\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_results[\"EC1\"] = blast_results[\"EC1\"].astype(str)\n",
    "blast_results[\"EC2\"] = blast_results[\"EC2\"].astype(str)\n",
    "blast_results[\"EC3\"] = blast_results[\"EC3\"].astype(str)\n",
    "blast_results[\"EC4\"] = blast_results[\"EC4\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '1.11',\n",
       " '1.14',\n",
       " '1.21',\n",
       " '2.5',\n",
       " '1.11.1',\n",
       " '1.14.11',\n",
       " '1.14.13',\n",
       " '1.14.14',\n",
       " '1.14.19',\n",
       " '1.14.20',\n",
       " '1.21.3',\n",
       " '2.5.1',\n",
       " '1.11.1.10',\n",
       " '1.14.11.16',\n",
       " '1.14.13.20',\n",
       " '1.14.19.56',\n",
       " '1.14.19.9',\n",
       " '1.14.20.15',\n",
       " '1.21.3.1',\n",
       " '2.5.1.63',\n",
       " '2.5.1.94']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blast_results.fillna(\"0\", inplace=True)\n",
    "blast_results_ = get_final_labels(blast_results, all_levels=True)\n",
    "blast_results_.drop(columns=[\"nan\"], inplace=True)\n",
    "labels_names = [ec_number.replace(\".0\", \"\") for ec_number in blast_results_.columns[18:].tolist()]\n",
    "labels_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1 3\n",
      "level 2 4\n",
      "level 3 6\n",
      "level 4 13\n"
     ]
    }
   ],
   "source": [
    "blast_predictions = np.array(blast_results_.iloc[:36, 18:])\n",
    "new_blast_predictions = convert_predictions_into_format(blast_predictions, labels_names, h_dataset_.iloc[:, 7:].columns)\n",
    "predictions_ensemble = determine_ensemble_predictions(2, new_predictions_esm1b, new_predictions_protein_bert, new_predictions_esm2_3b, new_blast_predictions)\n",
    "metrics_evaluation = pd.concat((metrics_evaluation, get_metrics(y_true, predictions_ensemble, h_dataset_.iloc[:, 7:].columns, [], \"Models Ensemble + BLASTp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1 3\n",
      "level 2 4\n",
      "level 3 6\n",
      "level 4 13\n"
     ]
    }
   ],
   "source": [
    "metrics_evaluation = pd.concat((metrics_evaluation, get_metrics(y_true, new_blast_predictions, h_dataset_.iloc[:, 7:].columns, [], \"BLASTp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy level 1</th>\n",
       "      <th>accuracy level 2</th>\n",
       "      <th>accuracy level 3</th>\n",
       "      <th>accuracy level 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNN ESM2 3B</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN ESM1b</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNN ProtBERT</th>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models Ensemble</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Models Ensemble + BLASTp</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLASTp</th>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          accuracy level 1  accuracy level 2  \\\n",
       "DNN ESM2 3B                       0.972222          0.972222   \n",
       "DNN ESM1b                         0.972222          0.972222   \n",
       "DNN ProtBERT                      0.861111          0.972222   \n",
       "Models Ensemble                   0.972222          0.972222   \n",
       "Models Ensemble + BLASTp          0.972222          0.972222   \n",
       "BLASTp                            0.861111          0.833333   \n",
       "\n",
       "                          accuracy level 3  accuracy level 4  \n",
       "DNN ESM2 3B                       0.555556          0.305556  \n",
       "DNN ESM1b                         0.555556          0.333333  \n",
       "DNN ProtBERT                      0.583333          0.250000  \n",
       "Models Ensemble                   0.555556          0.333333  \n",
       "Models Ensemble + BLASTp          0.555556          0.361111  \n",
       "BLASTp                            0.472222          0.361111  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_evaluation.to_csv(\"metrics_evaluation_halogenases.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
